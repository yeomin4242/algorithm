#!/usr/bin/env python3
"""
scripts/fetch_boj_problem.py
ë°±ì¤€ì—ì„œ ë¬¸ì œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""

import argparse
import json
import re
import requests
import time
from bs4 import BeautifulSoup

def get_solved_ac_info(problem_id):
    """solved.ac APIì—ì„œ ë¬¸ì œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        url = f"https://solved.ac/api/v3/problem/show?problemId={problem_id}"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            return {
                "title": data.get("titleKo", ""),
                "level": data.get("level", 0),
                "tags": [tag["displayNames"][0]["name"] for tag in data.get("tags", [])]
            }
    except Exception as e:
        print(f"solved.ac API ì˜¤ë¥˜: {e}")
    
    return {}

def scrape_boj_problem(problem_id):
    """ë°±ì¤€ì—ì„œ ë¬¸ì œ ì •ë³´ ìŠ¤í¬ë˜í•‘ (ì¬ì‹œë„ ë¡œì§ ì¶”ê°€)"""
    url = f"https://www.acmicpc.net/problem/{problem_id}"
    
    # â­ï¸ 1. ì‹¤ì œ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ë„ë¡ í—¤ë” ì •ë³´ ê°•í™”
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
    }

    # â­ï¸ 2. ìµœëŒ€ 3ë²ˆ, ê°„ê²©ì„ ë‘ê³  ì¬ì‹œë„
    for attempt in range(3):
        try:
            response = requests.get(url, headers=headers, timeout=15)
            # 4xx, 5xx ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚´
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ë¬¸ì œê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° (ì´ë•ŒëŠ” ì¬ì‹œë„í•  í•„ìš” ì—†ìŒ)
            if "ì¡´ì¬í•˜ì§€ ì•ŠëŠ”" in response.text or response.status_code == 404:
                return None
            
            # --- ì„±ê³µ ì‹œ, ë¬¸ì œ ì •ë³´ ì¶”ì¶œ ---
            problem_info = {}
            
            desc_elem = soup.find('div', {'id': 'problem_description'})
            problem_info['description'] = desc_elem.get_text(strip=True) if desc_elem else ""
            
            input_elem = soup.find('div', {'id': 'problem_input'})
            problem_info['input_format'] = input_elem.get_text(strip=True) if input_elem else ""
            
            output_elem = soup.find('div', {'id': 'problem_output'})
            problem_info['output_format'] = output_elem.get_text(strip=True) if output_elem else ""
            
            limit_elem = soup.find('div', {'id': 'problem_limit'})
            problem_info['limits'] = limit_elem.get_text(strip=True) if limit_elem else ""
            
            samples = []
            sample_inputs = soup.find_all('pre', {'id': re.compile(r'sample-input-\d+')}) # ID í˜•ì‹ ë³€ê²½ë¨
            sample_outputs = soup.find_all('pre', {'id': re.compile(r'sample-output-\d+')}) # ID í˜•ì‹ ë³€ê²½ë¨
            
            for i, (inp, out) in enumerate(zip(sample_inputs, sample_outputs)):
                samples.append({
                    "input": inp.get_text(strip=True),
                    "output": out.get_text(strip=True),
                })
            
            problem_info['samples'] = samples
            return problem_info # ì„±ê³µí–ˆìœ¼ë¯€ë¡œ ê²°ê³¼ ë°˜í™˜ ë° í•¨ìˆ˜ ì¢…ë£Œ
            
        except requests.exceptions.RequestException as e:
            print(f"ë°±ì¤€ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/3): {e}")
            if attempt < 2:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë¼ë©´
                wait_time = 2 ** (attempt + 1) # 2, 4ì´ˆ ê°„ê²©ìœ¼ë¡œ ëŒ€ê¸°
                print(f"{wait_time}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                time.sleep(wait_time)
            else:
                print("ìµœì¢… ìŠ¤í¬ë˜í•‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    return None # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

def main():
    parser = argparse.ArgumentParser(description='ë°±ì¤€ ë¬¸ì œ ì •ë³´ ìˆ˜ì§‘')
    parser.add_argument('--problem-id', required=True, help='ë°±ì¤€ ë¬¸ì œ ë²ˆí˜¸')
    args = parser.parse_args()
    
    problem_id = args.problem_id
    
    print(f"ğŸ“¥ ë¬¸ì œ {problem_id} ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
    
    # solved.ac ì •ë³´ ìˆ˜ì§‘
    solved_ac_info = get_solved_ac_info(problem_id)
    
    # ë°±ì¤€ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ë‚´ë¶€ì ìœ¼ë¡œ ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    boj_info = scrape_boj_problem(problem_id)
    
    if not boj_info:
        print(f"::error::ë¬¸ì œ {problem_id}ì˜ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        # ë¹ˆ ì •ë³´ë¡œë¼ë„ ê³„ì† ì§„í–‰
        boj_info = {
            "description": "ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨", "input_format": "", "output_format": "",
            "limits": "", "samples": []
        }
    
    # ì •ë³´ í†µí•©
    complete_info = {
        "problem_id": problem_id,
        "title": solved_ac_info.get("title", f"ë¬¸ì œ {problem_id}"),
        "level": solved_ac_info.get("level", 0),
        "tags": solved_ac_info.get("tags", []),
        **boj_info
    }
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open('problem_info.json', 'w', encoding='utf-8') as f:
        json.dump(complete_info, f, ensure_ascii=False, indent=2)
    
    # ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë³„ë„ ì €ì¥
    sample_tests = {
        "problem_id": problem_id,
        "test_cases": complete_info['samples']
    }
    
    with open('sample_tests.json', 'w', encoding='utf-8') as f:
        json.dump(sample_tests, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ë¬¸ì œ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ:")
    print(f"   - ì œëª©: {complete_info['title']}")
    print(f"   - ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤: {len(complete_info['samples'])}ê°œ")
    print(f"   - íƒœê·¸: {', '.join(complete_info['tags'][:3])}")

if __name__ == "__main__":
    main()