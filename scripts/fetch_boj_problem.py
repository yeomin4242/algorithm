#!/usr/bin/env python3
"""
scripts/fetch_boj_problem.py
ë°±ì¤€ì—ì„œ ë¬¸ì œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""

import argparse
import json
import re
import requests
import time
import random
from bs4 import BeautifulSoup

def get_solved_ac_info(problem_id):
    """solved.ac APIì—ì„œ ë¬¸ì œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        url = f"https://solved.ac/api/v3/problem/show?problemId={problem_id}"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            return {
                "title": data.get("titleKo", ""),
                "level": data.get("level", 0),
                "tags": [tag["displayNames"][0]["name"] for tag in data.get("tags", [])]
            }
    except Exception as e:
        print(f"solved.ac API ì˜¤ë¥˜: {e}")
    
    return {}

def get_random_user_agent():
    """ëœë¤ User-Agent ë°˜í™˜"""
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    ]
    return random.choice(user_agents)

def create_session():
    """ì„¸ì…˜ ìƒì„± ë° ì„¤ì •"""
    session = requests.Session()
    
    # ê³ ì • í—¤ë” ì„¤ì •
    session.headers.update({
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Cache-Control': 'max-age=0'
    })
    
    return session

def scrape_boj_problem_with_session(problem_id, session):
    """ì„¸ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ë°±ì¤€ ë¬¸ì œ ìŠ¤í¬ë˜í•‘"""
    url = f"https://www.acmicpc.net/problem/{problem_id}"
    
    try:
        # User-Agentë¥¼ ë§¤ë²ˆ ìƒˆë¡œ ì„¤ì •
        session.headers.update({'User-Agent': get_random_user_agent()})
        
        # ëœë¤ ì§€ì—° (1-3ì´ˆ)
        delay = random.uniform(1.0, 3.0)
        time.sleep(delay)
        
        response = session.get(url, timeout=20)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ë¬¸ì œê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
        if "ì¡´ì¬í•˜ì§€ ì•ŠëŠ”" in response.text or response.status_code == 404:
            return None
        
        # ë¬¸ì œ ì •ë³´ ì¶”ì¶œ
        problem_info = {}
        
        # ë¬¸ì œ ì„¤ëª…
        desc_elem = soup.find('div', {'id': 'problem_description'})
        problem_info['description'] = desc_elem.get_text(strip=True) if desc_elem else ""
        
        # ì…ë ¥ í˜•ì‹
        input_elem = soup.find('div', {'id': 'problem_input'})
        problem_info['input_format'] = input_elem.get_text(strip=True) if input_elem else ""
        
        # ì¶œë ¥ í˜•ì‹
        output_elem = soup.find('div', {'id': 'problem_output'})
        problem_info['output_format'] = output_elem.get_text(strip=True) if output_elem else ""
        
        # ì œí•œì‚¬í•­
        limit_elem = soup.find('div', {'id': 'problem_limit'})
        problem_info['limits'] = limit_elem.get_text(strip=True) if limit_elem else ""
        
        # ìƒ˜í”Œ ì…ì¶œë ¥
        samples = []
        sample_inputs = soup.find_all('pre', {'id': re.compile(r'sample-input-\d+')})
        sample_outputs = soup.find_all('pre', {'id': re.compile(r'sample-output-\d+')})
        
        for i, (inp, out) in enumerate(zip(sample_inputs, sample_outputs)):
            samples.append({
                "input": inp.get_text(),
                "output": out.get_text(),
            })
        
        problem_info['samples'] = samples
        return problem_info
        
    except Exception as e:
        raise e

def scrape_boj_problem_alternative_methods(problem_id):
    """ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ë°±ì¤€ ìŠ¤í¬ë˜í•‘ ì‹œë„"""
    
    # ë°©ë²• 1: ì¼ë°˜ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ (ê°œì„ ëœ í—¤ë”)
    print("  â†’ ë°©ë²• 1: ê°œì„ ëœ í—¤ë”ë¡œ ì‹œë„...")
    session = create_session()
    
    for attempt in range(2):
        try:
            result = scrape_boj_problem_with_session(problem_id, session)
            if result:
                print("  âœ… ë°©ë²• 1 ì„±ê³µ!")
                return result
        except Exception as e:
            print(f"  âŒ ë°©ë²• 1 ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/2): {e}")
            if attempt < 1:
                time.sleep(random.uniform(2.0, 4.0))
    
    # ë°©ë²• 2: ë°±ì¤€ ë©”ì¸ í˜ì´ì§€ ë¨¼ì € ë°©ë¬¸ í›„ ë¬¸ì œ í˜ì´ì§€ ì ‘ê·¼
    print("  â†’ ë°©ë²• 2: ë©”ì¸ í˜ì´ì§€ ìš°íšŒ ì ‘ê·¼...")
    try:
        session = create_session()
        
        # 1. ë©”ì¸ í˜ì´ì§€ ë¨¼ì € ë°©ë¬¸ (ì¿ í‚¤ ë° ì„¸ì…˜ ì„¤ì •)
        session.headers.update({'User-Agent': get_random_user_agent()})
        main_response = session.get('https://www.acmicpc.net/', timeout=15)
        main_response.raise_for_status()
        
        time.sleep(random.uniform(1.5, 2.5))
        
        # 2. ë¬¸ì œ ëª©ë¡ í˜ì´ì§€ ë°©ë¬¸
        problemset_response = session.get('https://www.acmicpc.net/problemset', timeout=15)
        problemset_response.raise_for_status()
        
        time.sleep(random.uniform(1.0, 2.0))
        
        # 3. ì‹¤ì œ ë¬¸ì œ í˜ì´ì§€ ì ‘ê·¼
        result = scrape_boj_problem_with_session(problem_id, session)
        if result:
            print("  âœ… ë°©ë²• 2 ì„±ê³µ!")
            return result
            
    except Exception as e:
        print(f"  âŒ ë°©ë²• 2 ì‹¤íŒ¨: {e}")
    
    # ë°©ë²• 3: ë” ê¸´ ì§€ì—°ì‹œê°„ê³¼ í•¨ê»˜ ì¬ì‹œë„
    print("  â†’ ë°©ë²• 3: ê¸´ ì§€ì—°ì‹œê°„ìœ¼ë¡œ ì¬ì‹œë„...")
    try:
        session = create_session()
        session.headers.update({'User-Agent': get_random_user_agent()})
        
        # 5-8ì´ˆ ëŒ€ê¸°
        time.sleep(random.uniform(5.0, 8.0))
        
        result = scrape_boj_problem_with_session(problem_id, session)
        if result:
            print("  âœ… ë°©ë²• 3 ì„±ê³µ!")
            return result
            
    except Exception as e:
        print(f"  âŒ ë°©ë²• 3 ì‹¤íŒ¨: {e}")
    
    print("  âŒ ëª¨ë“  ìŠ¤í¬ë˜í•‘ ë°©ë²• ì‹¤íŒ¨")
    return None

def get_fallback_samples(problem_id):
    """ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ ì•Œë ¤ì§„ ë¬¸ì œë“¤ì˜ ìƒ˜í”Œ ì œê³µ"""
    known_samples = {
        "1000": [{"input": "1 2", "output": "3"}],
        "2557": [{"input": "", "output": "Hello World!"}],
        "1001": [{"input": "1 -1", "output": "0"}],
        "10998": [{"input": "1 2", "output": "2"}],
        "1008": [{"input": "1 3", "output": "0.33333333333333333333"}],
        "10869": [{"input": "7 3", "output": "10\n4\n21\n2\n1"}],
        "10171": [{"input": "", "output": "\\    /\\\n )  ( ')\n(  /  )\n \\(__)|"}],
        "10172": [{"input": "", "output": "|\\_/|\n|q p|   /}\n( 0 )\"\"\"\\\n|\"^\"`    |\n||_/=\\\\__|"}]
    }
    
    return known_samples.get(problem_id, [])

def main():
    parser = argparse.ArgumentParser(description='ë°±ì¤€ ë¬¸ì œ ì •ë³´ ìˆ˜ì§‘')
    parser.add_argument('--problem-id', required=True, help='ë°±ì¤€ ë¬¸ì œ ë²ˆí˜¸')
    args = parser.parse_args()
    
    problem_id = args.problem_id
    
    print(f"ğŸ“¥ ë¬¸ì œ {problem_id} ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
    
    # solved.ac ì •ë³´ ìˆ˜ì§‘
    solved_ac_info = get_solved_ac_info(problem_id)
    
    # ë°±ì¤€ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì‹œë„)
    boj_info = scrape_boj_problem_alternative_methods(problem_id)
    
    if not boj_info:
        print(f"::warning::ë¬¸ì œ {problem_id}ì˜ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # í´ë°± ìƒ˜í”Œ ì‚¬ìš©
        fallback_samples = get_fallback_samples(problem_id)
        
        boj_info = {
            "description": f"ë¬¸ì œ {problem_id} (ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨)",
            "input_format": "ì…ë ¥ í˜•ì‹ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "output_format": "ì¶œë ¥ í˜•ì‹ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "limits": "ì œí•œì‚¬í•­ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "samples": fallback_samples
        }
        
        if fallback_samples:
            print(f"  â†’ ì•Œë ¤ì§„ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ {len(fallback_samples)}ê°œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # ì •ë³´ í†µí•©
    complete_info = {
        "problem_id": problem_id,
        "title": solved_ac_info.get("title", f"ë¬¸ì œ {problem_id}"),
        "level": solved_ac_info.get("level", 0),
        "tags": solved_ac_info.get("tags", []),
        **boj_info
    }
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open('problem_info.json', 'w', encoding='utf-8') as f:
        json.dump(complete_info, f, ensure_ascii=False, indent=2)
    
    # ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë³„ë„ ì €ì¥
    sample_tests = {
        "problem_id": problem_id,
        "test_cases": complete_info['samples']
    }
    
    with open('sample_tests.json', 'w', encoding='utf-8') as f:
        json.dump(sample_tests, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ë¬¸ì œ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ:")
    print(f"   - ì œëª©: {complete_info['title']}")
    print(f"   - ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤: {len(complete_info['samples'])}ê°œ")
    print(f"   - íƒœê·¸: {', '.join(complete_info['tags'][:3])}")

if __name__ == "__main__":
    main()